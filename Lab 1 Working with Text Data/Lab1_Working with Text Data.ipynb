{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618bcebd-dbbf-4fc8-ae4c-86873414455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text:\n",
      " Hello, this is a sample text file.\n",
      "This is the second line.\n"
     ]
    }
   ],
   "source": [
    "# Read the content of the text file \n",
    "with open('sample.txt', 'r', encoding='utf-8') as file: \n",
    "    text_data = file.read() \n",
    "print(\"Raw Text:\\n\", text_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dba644-042d-460f-b886-704b4b2dbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in another file \n",
    "with open('stored_text.txt', 'w', encoding='utf-8') as file: \n",
    "    file.write(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253df2a5-3e73-4da5-97dc-e3ef8acb59e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews:\n",
      " 0    The product is amazing!\n",
      "1     Worst experience ever!\n",
      "Name: Review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Read the CSV file \n",
    "df = pd.read_csv('reviews.csv') \n",
    "\n",
    "#Extract\n",
    "print(\"Reviews:\\n\", df['Review'].head()) \n",
    "\n",
    "# Save the reviews column to a text file \n",
    "df['Review'].to_csv('stored_reviews.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947f0e51-908f-4a93-aeb3-e49769744056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two rows:\n",
      "    ID                   Review\n",
      "0   1  The product is amazing!\n",
      "1   2   Worst experience ever!\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file \n",
    "df_excel = pd.read_excel('reviews.xlsx', engine='openpyxl') \n",
    "print(\"First two rows:\\n\", df_excel.head(2)) \n",
    "\n",
    "# Save the first two rows to a text file \n",
    "df_excel.head(2).to_csv('extracted_excel.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd084b5-5339-4a41-ad88-bd720c45875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted City: New York\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    " \n",
    "# Read the JSON file \n",
    "with open('social_data.json', 'r', encoding='utf-8') as file: \n",
    "    data = json.load(file) \n",
    "print(\"Extracted City:\", data['city']) \n",
    " \n",
    "# Store the extracted city to a file \n",
    "with open('stored_city.txt', 'w', encoding='utf-8') as file: \n",
    "    file.write(data['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c9d22f-10d9-483c-abcf-2af820966ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Title: AI is transforming industries\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    " \n",
    "# Parse the XML file \n",
    "tree = ET.parse('news.xml') \n",
    "root = tree.getroot() \n",
    " \n",
    "for article in root.findall('article'): \n",
    "    title = article.find('title').text \n",
    "    print(\"Extracted Title:\", title) \n",
    " \n",
    "# Store the extracted title to a file \n",
    "with open('stored_titles.txt', 'w', encoding='utf-8') as file: \n",
    "    for article in root.findall('article'): \n",
    "        title = article.find('title').text \n",
    "        file.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b32e8c3a-3c48-4580-b0da-8fa2c6812093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e62708c-12ae-43e2-8886-effec8bbafc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDF Text:\n",
      " This is a sample PDF document.  \n",
      "AI is transforming industries and automation.  \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "\n",
    "# Read the PDF file \n",
    "with open('document.pdf', 'rb') as file: \n",
    "    reader = PyPDF2.PdfReader(file) \n",
    "    text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text()) \n",
    "    \n",
    "# Print the extracted text \n",
    "print(\"Extracted PDF Text:\\n\", text) \n",
    "\n",
    "# Store the extracted text in a file \n",
    "with open('stored_pdf_text.txt', 'w', encoding='utf-8') as output: \n",
    "    output.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b4708-5468-45f4-9320-2fc9bce02c15",
   "metadata": {},
   "source": [
    "Exercise No1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d13648-27f4-4f9f-9127-61a44a3d1e3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDF Text:\n",
      " Business Proposal  \n",
      "The Revolution is Coming  \n",
      "Leverage agile frameworks to provide a robust synopsis for high level  \n",
      "overviews. Iterative approaches to corporate strategy foster collaborative  \n",
      "thinking to further the overall value proposition. Organically grow the  \n",
      "holistic world view of disruptive innovation via workplace diversity and  \n",
      "empowerment.  \n",
      "Bring to the table win -win survival strategies to ensure proactive  \n",
      "domination. At the end of the day, going forward, a new normal that has  \n",
      "evolved from generation X is on the runway heading towards a streamlined  \n",
      "cloud solution. User generated content in real -time will have multi ple \n",
      "touchpoints for offshoring.  \n",
      "Capitalize on low hanging fruit to identify a ballpark value added activity to  \n",
      "beta test. Override the digital divide with additional clickthroughs from  \n",
      "DevOps. Nanotechnology immersion along the information highway will  \n",
      "close the loop on focusing solely on the bottom line.  \n",
      "Podcasting operational change management inside of workflows to  \n",
      "establish a framework. Taking seamless key performance indicators offline  \n",
      "to maximise the long tail. Keeping your eye on the ball while perfo rming a  \n",
      "deep dive on the start -up mentality to derive convergence on crossplatform  \n",
      "integration.  \n",
      "Collaboratively administrate empowered markets via plug -and-play \n",
      "networks. Dynamically procrastinate B2C users after installed base  \n",
      "benefits. Dramatically visua lize customer directed convergence without  \n",
      "revolutionary ROI.  \n",
      "Efficiently unleash cross -media information without cross -media value.  \n",
      "Quickly maximize timely deliverables for real -time schemas. Dramatically  \n",
      "maintain clicks -and-mortar solutions without funct ional solutio ns. \n",
      "  \n",
      "AUTHORS:  \n",
      "Amy Baker, Finance Chair, x345, abaker@ourcompany.com  \n",
      "Chris Donaldson, Accounting Dir., x621, cdonaldson@ourcompany.com  \n",
      "Erin Freeman, Sr. VP, x879, efreeman@ourcompany.com  \n"
     ]
    }
   ],
   "source": [
    "#Extract text from all pages of Business_Proposal.pdf and save it in business_proposal_all.txt. \n",
    "\n",
    "import PyPDF2 \n",
    "\n",
    "# Read the PDF file \n",
    "with open('Business_Proposal.pdf', 'rb') as file: \n",
    "    reader = PyPDF2.PdfReader(file) \n",
    "    text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text()) \n",
    "    \n",
    "# Print the extracted text \n",
    "print(\"Extracted PDF Text:\\n\", text) \n",
    "\n",
    "# Store the extracted text in a file \n",
    "with open('business_proposal_all.txt', 'w', encoding='utf-8') as output: \n",
    "    output.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e0599-6033-4e5c-8df5-48417d2d67aa",
   "metadata": {},
   "source": [
    "Exercise No2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d596275-18b7-420f-8df5-7977c27757d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDF Text:\n",
      " AUTHORS:  \n",
      "Amy Baker, Finance Chair, x345, abaker@ourcompany.com  \n",
      "Chris Donaldson, Accounting Dir., x621, cdonaldson@ourcompany.com  \n",
      "Erin Freeman, Sr. VP, x879, efreeman@ourcompany.com  \n"
     ]
    }
   ],
   "source": [
    "#Extract text from only page 2 of Business_Proposal.pdf and save it in business_proposal_page_2.txt. \n",
    "\n",
    "import PyPDF2 \n",
    "\n",
    "# Read the PDF file \n",
    "with open('Business_Proposal.pdf', 'rb') as file: \n",
    "    reader = PyPDF2.PdfReader(file) \n",
    "    text = reader.pages[1].extract_text()\n",
    "    \n",
    "# Print the extracted text \n",
    "print(\"Extracted PDF Text:\\n\", text) \n",
    "\n",
    "# Store the extracted text in a file \n",
    "with open('business_proposal_page_2.txt', 'w', encoding='utf-8') as output: \n",
    "    output.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50eb0f-0a0e-4b1e-b69a-37260d1006f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
